<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-12-10T16:21:16-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Simina’s blog</title><entry><title type="html">2018: Year in review</title><link href="http://localhost:4000/Year-in-review/" rel="alternate" type="text/html" title="2018: Year in review" /><published>2018-12-10T00:00:00-05:00</published><updated>2018-12-10T00:00:00-05:00</updated><id>http://localhost:4000/Year-in-review</id><content type="html" xml:base="http://localhost:4000/Year-in-review/">&lt;p&gt;Since it’s close to the end of the year, I’m going to 
spend some time reflecting on it. One of the major challenges of a research career is that
there are often few concrete achievements and even when something good happens, it feels like
rejection is right around the corner. As a result, I decided at the very beginning of the year to keep
a running list of achievements, so that I could have something to cheer me up a bit in between the long
stretches of waiting. I wanted to include products that weren’t necessarily full-fledged papers,
including blog posts, talk acceptances, big grant submissions (not just acceptances, since those are way rare!)
This year did end up being really good in terms of paper acceptances and I think that
some of the smaller things allowed me to gain the extra confidence and ability to drive home
some bigger things.
Here is my list:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I had a tweet/blog post on regression that &lt;a href=&quot;https://twitter.com/siminaboca/status/951201399563587589&quot;&gt;kind of went viral&lt;/a&gt; Where viral = viral for me. I was really happy about this, since these were thoughts that
were swirling in my head since grad school and it was nice to get them out and also get a bit of validation by hearing how others found it useful
(January 10)&lt;/li&gt;
  &lt;li&gt;I joined the &lt;a href=&quot;https://github.com/greenelab/deep-review&quot;&gt;“deep review” project&lt;/a&gt; (collaboratively written paper reviewing deep learning in biomedical research). I don’t work in deep learning per se, but I like to think a lot
about how different methods should be applied and what their caveats are. It was an awesome learning experience being on this kind of modern collaborative project and I’m really indebted to the &lt;a href=&quot;(https://twitter.com/NewPI_Slack).&quot;&gt;New PI Slack (NPIS) group&lt;/a&gt;.
I had read a preprinted version of the paper and had a comment on an example that considered Duchenne muscular dystrophy, a disease that I have worked on before. I asked
&lt;a href=&quot;https://twitter.com/GreeneScientist&quot;&gt;Casey Greene&lt;/a&gt; about it and he encouraged me to go ahead and make the edits on GitHub. I ended up contributing enough to the new version to be listed as an author. (January 19)&lt;/li&gt;
  &lt;li&gt;My &lt;a href=&quot;http://ascopubs.org/doi/full/10.1200/PO.17.00175&quot;&gt;commentary comparing biocuration to systematic reviews&lt;/a&gt; was accepted in JCO PO. I felt good about this since this was again something that I had been thinking about for a while now so I decided at some point last
year to just put my thoughts on paper. I had some general ideas so came up with a short draft, then recruited some other super knowledgeable folks to flesh out the details. This is the first time this kind of project has come
together for me. (January 19)&lt;/li&gt;
  &lt;li&gt;By the end of February, I already had 4 papers accepted (the “deep review,” the commentary paper, 2 other collaborative papers.)&lt;/li&gt;
  &lt;li&gt;I gave a talk a Brown University, invited by my friend, former NCI postdoc colleague, and coauthor &lt;a href=&quot;https://twitter.com/orpanag&quot;&gt;Orestis Panagiotou&lt;/a&gt;. (April 10)&lt;/li&gt;
  &lt;li&gt;Another paper was accepted by JCO PO that I was a co-author on, considering an &lt;a href=&quot;http://ascopubs.org/doi/10.1200/PO.17.00296&quot;&gt;eye-tracking study&lt;/a&gt; for usability of molecular diagnostic reports. I was involved in the original study design and grant submission for it
and it was led by a former ICBI postdoc, &lt;a href=&quot;https://twitter.com/VishakhaSharma_&quot;&gt;Vishakha Sharma&lt;/a&gt;. It was also a really important project for the center and I was very happy to see it completed. (May 4)&lt;/li&gt;
  &lt;li&gt;The supplement to my R21 grant was officially awarded! My R21 is funded through the &lt;a href=&quot;https://nciphub.org/groups/itcr&quot;&gt;NCI Informatics Technology for Cancer Research (ITCR) program&lt;/a&gt; and the supplement is for a collaboration with a group funded through the 
Innovative Molecular Analysis Technologies (IMAT) program. I had applied for it last year so kind of wondered whether it was “fair” to list it as an accomplishment for the year. Then I decided that I might as well. (May 21)&lt;/li&gt;
  &lt;li&gt;I submitted an application for an &lt;a href=&quot;https://grants.nih.gov/grants/guide/pa-files/PAR-17-190.html&quot;&gt;NIGMS R35 “MIRA” grant&lt;/a&gt;. 
This was my biggest application to date as a PI! I am again indebted to NPIS for finding out about this! It’s a grant that is meant to fund early stage investigators’ NIGMS-related research programs, 
as opposed to individual projects, which made it easier to write (for me at least!) than a regular project-driven grant. The chances of acceptance are always low for any individual grant, but I felt good just knowing that I could apply for this kind of big thing. If it doesn’t get
funded, I will apply for sure next year as well! (September 28)&lt;/li&gt;
  &lt;li&gt;By mid-October, I had 6 papers accepted (the ones mentioned above plus one more collaborative paper.)&lt;/li&gt;
  &lt;li&gt;I got a talk accepted at the &lt;a href=&quot;https://meetings.cshl.edu/meetings.aspx?meet=DATA&amp;amp;year=18&quot;&gt;CSHL Biological Data Science&lt;/a&gt; meeting (&lt;a href=&quot;https://github.com/SiminaB/Presentations/blob/master/CSHL%20Bio%20Data%20Science%202018/Boca_CSHL.pdf&quot;&gt;slides here&lt;/a&gt;).
(October 10)&lt;/li&gt;
  &lt;li&gt;My &lt;a href=&quot;https://peerj.com/articles/6035/&quot;&gt;paper&lt;/a&gt; with my former PhD adviser &lt;a href=&quot;http://jtleek.com/&quot;&gt;Jeff Leek&lt;/a&gt; on estimating the false-discovery rate (FDR) conditional on covariates was finally accepted by PeerJ. More on this paper below. For now - let me just say this was a very long process and it was such a relief to have it
officially out. (October 24)&lt;/li&gt;
  &lt;li&gt;I also got a talk accepted at the &lt;a href=&quot;https://www.amia.org/summit2019&quot;&gt;AMIA 2019 Informatics Summit&lt;/a&gt;. (October 30)&lt;/li&gt;
  &lt;li&gt;I was also invited to give talks next year to the Breast Oncology Program at UCSF and the Bioconductor conference, which will be in New York.  (November)&lt;/li&gt;
  &lt;li&gt;I posted a &lt;a href=&quot;https://www.biorxiv.org/content/early/2018/11/23/475590&quot;&gt;preprint&lt;/a&gt; for metabolic biomarkers in a mouse model of Duchenne muscular dystrophy, which I’m a co-first author on. (November 23)&lt;/li&gt;
  &lt;li&gt;I read 8 books! Hoping to finish one more before the end of the year. They included books about science, like The Emperor of All Maladies, She Had her Mother’s Laugh and The Immortal Life of Henrietta Lacks, and books about time management and people management, like Deep
Work and 168 Hours.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As I said before, this has been a really good year! 
However, most of the projects that were completed were things that I had started a long time ago. The FDR paper, for example, originated in an idea that Jeff had, based on some of my PhD work, that he wrote a &lt;a href=&quot;https://simplystatistics.org/2013/06/13/false-discovery-rate-regression-cc-nsas-prism/&quot;&gt;blog post&lt;/a&gt; on June 13, 2013. Just for perspective, since
that time, I switched from being a postdoc at NCI to being faculty at &lt;a href=&quot;https://icbi.georgetown.edu/&quot;&gt;ICBI&lt;/a&gt;, I had a second child, and 
&lt;a href=&quot;https://www.bbc.com/sport/tennis/44425403&quot;&gt;Simona Halep won the French Open&lt;/a&gt; 
(she reached her first Grand Slam final in 2014 and played two others before winning in 2018, all during the time it took for this paper to be completed). 
Of course, the work took a fair amount of time to complete,
but a substantial amount of time was also spent looking for a good home for the paper. In fact, we first posted a &lt;a href=&quot;https://www.biorxiv.org/content/early/2015/12/30/035675&quot;&gt;preprint&lt;/a&gt; of what’s now a super outdated version of that project on December 30, 2015.
The great thing about posting it as a preprint was that it did get read a fair bit and even included in a &lt;a href=&quot;https://www.biorxiv.org/content/early/2018/10/31/458786&quot;&gt;comparison&lt;/a&gt; of methods for FDR control, in which it was shown to have a good performance.&lt;/p&gt;

&lt;p&gt;Some other things felt very satisfying because they were the result of seeds I had planted a while ago. For example, I had wanted to do more work in Duchenne muscular dystrophy, since my &lt;a href=&quot;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0153461&quot;&gt;2016&lt;/a&gt; work on metabolic biomarkers for this disorder.
I kept asking collaborators about it until the right project came along. I wanted to be able to present more at conferences/seminars and get both more talks when submitting abstracts and (any?) invited talks. 
I whined about this for a while, then actually started taking some actions to improve the situation. For example,
I asked around about what the most appropriate conferences would be and put myself out there more, both by talking to friends and colleagues (including &lt;a href=&quot;https://icbi.georgetown.edu/Madhavan&quot;&gt;Subha Madhavan&lt;/a&gt;, our center director, as well as NPIS),
and by being more aggressive about self-advertising on Twitter.&lt;/p&gt;

&lt;p&gt;That being said… If you notice, there was still that seemingly “empty” time between May and September when apparently 
nothing got done. I felt it acutely at the time too. I mean, I was definitely working (as well as taking some family trips!) 
and hopefully planting seeds
for some good things that will happen 2019-2023.
I also got some reading done during that time: I feel really good about the 8 books I’ve read; the number is surely low 
compared to many, but I’ve gone through years of
not being able to complete any books, so getting back on track feels very nice. In 2019 I want to be somewhat more
deliberate about planting seeds during these “dead periods” but also try to worry a bit less about them.&lt;/p&gt;</content><author><name></name></author><summary type="html">Since it’s close to the end of the year, I’m going to spend some time reflecting on it. One of the major challenges of a research career is that there are often few concrete achievements and even when something good happens, it feels like rejection is right around the corner. As a result, I decided at the very beginning of the year to keep a running list of achievements, so that I could have something to cheer me up a bit in between the long stretches of waiting. I wanted to include products that weren’t necessarily full-fledged papers, including blog posts, talk acceptances, big grant submissions (not just acceptances, since those are way rare!) This year did end up being really good in terms of paper acceptances and I think that some of the smaller things allowed me to gain the extra confidence and ability to drive home some bigger things. Here is my list:</summary></entry><entry><title type="html">Omics exploratory data analysis checklist</title><link href="http://localhost:4000/Omics-exploratory-analysis-checklist/" rel="alternate" type="text/html" title="Omics exploratory data analysis checklist" /><published>2018-09-05T00:00:00-04:00</published><updated>2018-09-05T00:00:00-04:00</updated><id>http://localhost:4000/Omics-exploratory-analysis-checklist</id><content type="html" xml:base="http://localhost:4000/Omics-exploratory-analysis-checklist/">&lt;p&gt;This is a non-exhaustive checklist of exploratory data analysis (EDA) checks I do for omics datasets + any associated demographic or meta-data, as a first step (after some basic reading in the data and basic preprocessing.)
There are many resources for this. I am personally indebted to my Rafa Irizarry, Jeff Leek, Roger Peng, Karl Broman among others for many of these tips.
Note that I tend to spend maybe 90% of total analysis time doing this kind of EDA and don’t usually start doing much modeling until I do at least an initial first pass of EDA and discuss 
results with the rest of the team and/or investigators who generated the data/provided the samples. See also &lt;a href=&quot;http://r4ds.had.co.nz/diagrams/data-science.png&quot;&gt;Hadley Wickham’s diagram&lt;/a&gt; representing the data analytic process.&lt;/p&gt;

&lt;h3 id=&quot;general-tips&quot;&gt;General tips&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Science tip: Make sure you understand the study design. Sometimes things aren’t totally clear until after the EDA though. Are there
biological replicates, technical replicates, or both? What does “biological replicate” even mean? (Same person, different part of the tumor, but same date?
Same person, different time? Same person, one measurement before treatment and one measurement after treatment?) Make sure you have the variables
that will allow you to take the study design into consideration (eg may need a variable for “time point,” a variable for “individual” etc)&lt;/li&gt;
  &lt;li&gt;Technical tip: If using R, always make sure you include NAs (for example, in the table function, this not the default - have to specify ‘useNA = “ifany”’)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;specific-steps&quot;&gt;Specific steps&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Check the number of samples, tabulate by all possible variables (such as case/control, disease type, sex, study site etc) - make sure there are no
NAs there, make sure variables are standardized (eg not have M = Male = male, breast cancer = Breast cancer = Neoplasm, breast)&lt;/li&gt;
  &lt;li&gt;Consider any crosstabulations that may make sense and may inform later analyses, for example case/control x study site, sex x SES, race x SES etc&lt;/li&gt;
  &lt;li&gt;Check the ranges of the data matrix/matrices. Make sure there are no NAs here. If there are, try to figure out why (eg clinical data may be missing, but
may aso have certain measurements above/below limit of detection, like in metabolomics or proteomics). Make sure that ranges all make sense (again, 0s
can indicate value below limit of detection - need to figure out what to do with this before applying log transforms; if study is on adolescents, make sure that no one
has age 1 or 30; make sure there are no weird codings for “missing data,” like 999 or -9 etc).  Do this using both tables of quantiles and histograms.&lt;/li&gt;
  &lt;li&gt;If you have NAs or 0s for the omics dataset, get an idea of how prevalent these are. Are there some samples that are mostly NA/0? Are there some metabolites that are NA/0
in a large fraction of samples? I’ve used the cutoff of 5% before i.e. only use metabolites that are &amp;gt; 0 in 95% of the samples and for those samples, replace the 0s with the
smallest value above 0. That seems to work OK. If some metabolites are 0 in, say, 50% of the samples, you probably don’t want to use the (transformed) metabolite intensities
as outcomes in a linear regression and need to decide on a different model (this may be OK if the metabolite is caffeine or cotinine, which is present in smokers, for example - 
not all metabolites will be present in everyone, but if you see this for creatine or glucose, there may be an issue)&lt;/li&gt;
  &lt;li&gt;If there are clinical outcomes, make sure you understand them or how to calculate them. For example, if needed, make sure that you can calculate survival (so you have the appropriate dates and understand the censoring mechanism etc.)&lt;/li&gt;
  &lt;li&gt;If anything has units, make sure you know what they are (eg is age in years or months?)&lt;/li&gt;
  &lt;li&gt;Make sure you have data on batches or run order; if not, try to get those variables (for example, run dates for microarrays, run order
for metabolomics data)&lt;/li&gt;
  &lt;li&gt;Make boxplots, PCA plots (use scale=TRUE if using prcomp, which is not the default) of log-transformed omics features, ordering and/or color-coding by the various
variables, especially batch/run order. This is probably the most important step in looking for possible artifacts/confounders. Note that even if there is no clear
confounding by batch/run order, there could still be confounding by other variables due to sample collection/processing &lt;em&gt;before&lt;/em&gt; the samples were actually run (for
example, if cases were collected in one hospital and controls in another hospital.) Some people like to do hierarchical clustering here, I personally prefer PCA plots. Make
sure the boxplots are before quantile normalization (QN), otherwise all the samples will all look the same (and we know that QN does not necessarily remove
batch effects and could actually make it worse). Clear shifts by batch can be bad in boxplots, but I’ve also seen cases where the median goes down and the variance
increases as the run order increases (so signal gets lower and messier) etc. Sometimes I’ll fit some regressions of PC1 and PC2 on the different variables - including
the batch/run order variables - to get a better idea of what’s going on, but I don’t think that’s always necessary.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">This is a non-exhaustive checklist of exploratory data analysis (EDA) checks I do for omics datasets + any associated demographic or meta-data, as a first step (after some basic reading in the data and basic preprocessing.) There are many resources for this. I am personally indebted to my Rafa Irizarry, Jeff Leek, Roger Peng, Karl Broman among others for many of these tips. Note that I tend to spend maybe 90% of total analysis time doing this kind of EDA and don’t usually start doing much modeling until I do at least an initial first pass of EDA and discuss results with the rest of the team and/or investigators who generated the data/provided the samples. See also Hadley Wickham’s diagram representing the data analytic process.</summary></entry><entry><title type="html">Tips on making presentation slides</title><link href="http://localhost:4000/Tips-on-making-presentation-slides/" rel="alternate" type="text/html" title="Tips on making presentation slides" /><published>2018-02-09T00:00:00-05:00</published><updated>2018-02-09T00:00:00-05:00</updated><id>http://localhost:4000/Tips-on-making-presentation-slides</id><content type="html" xml:base="http://localhost:4000/Tips-on-making-presentation-slides/">&lt;p&gt;Below is a non-exhaustive list of recommendation on making presentation slides, focusing on 
presenting biostatistics or bioinformatics projects. There are many amazing resources out there. I internalized much
of the advice given to me by many awesome official and unofficial mentors (Jeff Leek, Giovanni
Parmigiani, Josh Sampson, Tom Louis, @theeffortreport with Roger Peng and Elizabeth Matsui, and
@NSSDeviations with Hilary Parker and Roger Peng, to list a few) and the goal here is to
pass some of it along to my students rather than to come up with a comprehensive list.&lt;/p&gt;

&lt;p&gt;My students tend to be from Biostatistics and Bioinformatics, so their projects involve both
scientific and statistical or computational aspects. This presents additional challenges,
given both the interdisciplinary nature of the work and the potential audiences.&lt;/p&gt;

&lt;h4 id=&quot;major-guiding-principles&quot;&gt;Major guiding principles:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Build the entire presentation by starting from the general scientific question you are trying 
to answer. Why are you studying this problem? Why is it interesting? Move from there into
the more technical aspects, but do so in a logical manner, still focusing on the
overall framework - Are you testing a specific hypothesis? Are you providing tools for exploratory
data analysis?&lt;/li&gt;
  &lt;li&gt;Know your audience: If statistical, you may need to introduce biology terms like the different kinds of mutations - e.g. missense, nonsense. If biomedical, do not assume knowledge of statistics past t-test or programming knowledge.&lt;/li&gt;
  &lt;li&gt;You should go into technical details only after you introduce the big picture/framework. For example,
details like “We use grouped LASSO with 10-fold crossvalidation” or “We used the following
10 packages in R” do not need to be introduced up front. Methods and tools are very important but they should
not be introduced without making it clear why you are doing so. Otherwise, you risk confusing people or making them
think that you are confusing an approach with the tool used to implement it (e.g. “we use the coxph command” instead
of “we fit a Cox proportional hazard model”)&lt;/li&gt;
  &lt;li&gt;Always assume your audience is intelligent and educated, but don’t be too worried about presenting things that
are too basic or “known by everyone,” especially in the first few slides (also see &lt;em&gt;Know your audience&lt;/em&gt; above - folks
will know much more about their own fields than about other fields.) This may either make people feel good that they
understand something or actually help them learn something new.&lt;/li&gt;
  &lt;li&gt;Practice and iterate! Schedule practice presentations with your mentors and friends! 
Try not to take criticism personally during either the practice presentations (you want to improve!)
or during the actual presentation, although this can be hard.&lt;/li&gt;
  &lt;li&gt;Think about things you really liked in some presentations you’ve seen and try to emulate them and also about things you really didn’t like
and try not to be that presenter.&lt;/li&gt;
  &lt;li&gt;Less can be more. Simplify, simplify, simplify! See below.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;less-is-often-more&quot;&gt;Less is often more:&lt;/h4&gt;

&lt;p&gt;During the iteration process, I try to always think about how to simplify everything and reduce the amount of text/talking. Maybe I’ll
come up with a simpler table with fewer columns or even replace a few bullet points with a diagram. Some specific advice on this:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Don’t be the person who says: “I know you can’t really read this text, but it says…” If it’s not readable it’s too small.
If it’s too small it’s probably because you’re trying to cram too much in. Tables that are OK for reports/papers are usually
way too large to fit on slides or present in a way that keeps the audience engaged.&lt;/li&gt;
  &lt;li&gt;Similarly, don’t have a 4x4 grid of plots but say “You only really need to focus on these 2 plots.” Only have those 2 plots then.
If you find that you’re not able to get into a specific plot due to time constraints, remove it.
Unless the plots are very closely related, it may be better to have them on separate slides.&lt;/li&gt;
  &lt;li&gt;The outline slide debate: Some people feel very strongly that you should have an outline slide, others that you should not.
I fall into the second camp, though I’m not totally dogmatic about this. I prefer to have a slide introducing the project and the 
overall goals, then go right into the presentation. Especially for a 15-20 minute presentation, you probably don’t want/need
to spend time on an outline slide where you say things like “I will start by introducing the problem,” “I will check the method
via simulations,” and definitely not “Finally, I will conclude with the conclusions.”&lt;/li&gt;
  &lt;li&gt;Try not to prepare more than one slide per minute (videos/demos are extra.) Be respectful of your audience’s time and try to 
do a good job conveying the gist of your work in the assigned time (ending a couple of minutes early is OK and way better than
ending 15 minutes late!)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;specific-advice-for-individual-slides&quot;&gt;Specific advice for individual slides:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Give slides meaningful titles that are as self-contained as possible.&lt;/li&gt;
  &lt;li&gt;Don’t include large blocks of text and try not to have more than 3-4 bullet points.&lt;/li&gt;
  &lt;li&gt;Try not to have many/any equations for a biomedical or mixed audience. I do usually have some when presenting
for a statistical audience.&lt;/li&gt;
  &lt;li&gt;Label plots clearly and present them by first saying what the plot is assessing/presenting. This should 
also be in the slide/plot title. You not need a plot title if the slide title is specific enough. In fact, this 
will help you save on space and allow you to make things bigger/more readable.&lt;/li&gt;
  &lt;li&gt;If using R to make the plots, change the x and y labels from the default variable names in R so that they’re more easily understandable. 
For example, you don’t want to distract the audience and spend extra time saying “Time.patient represents the overall survival time in weeks” - 
instead change that label to read “Overall survival time (in weeks).”&lt;/li&gt;
  &lt;li&gt;Use large fonts and large labels on figures/tables (will probably need to increase font from defaults in R).&lt;/li&gt;
  &lt;li&gt;Try to use high-resolution figures. Projectors often make things fuzzier!&lt;/li&gt;
  &lt;li&gt;Try to be color-blind friendly by not using the red/green scheme. Colors can get messed up when projecting anyway, so
it may be better to use them sparingly and not have more than 3-4 different colors per plot. This depends a lot on your
application and may not always be possible, but again, think about where you can simplify!&lt;/li&gt;
  &lt;li&gt;Do not show a large number of significant digits. It is almost never necessary to show more than 2. The difference
between p = 1.9 x 10^-19 and p = 1.942529058202 x 10^-19 is very small and the latter is very distacting.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;you-gotta-start-somewhere&quot;&gt;You gotta start somewhere!&lt;/h4&gt;

&lt;p&gt;While you should consider the advice above, make sure it doesn’t give you writer’s block/analysis paralysis. I often
start out with a rough version by cutting/pasting from my manuscript/notes/R output, then think about how to focus it,
simplify it, and prettify it.&lt;/p&gt;

&lt;h4 id=&quot;practice-and-iterate-many-times&quot;&gt;Practice and iterate many times!&lt;/h4&gt;

&lt;p&gt;This was already stated before, but cannot be overstated. It depends on the stage of your career and the type of talk as well,
of course (update to small group, final presentation for your degree, job interview etc), but in general it is very important.
Only by practicing can you see that you are belaboring some things or that certain plots/tables don’t fit in in their current form.
Make sure you give yourself enough lead time to be able to do this.&lt;/p&gt;</content><author><name></name></author><summary type="html">Below is a non-exhaustive list of recommendation on making presentation slides, focusing on presenting biostatistics or bioinformatics projects. There are many amazing resources out there. I internalized much of the advice given to me by many awesome official and unofficial mentors (Jeff Leek, Giovanni Parmigiani, Josh Sampson, Tom Louis, @theeffortreport with Roger Peng and Elizabeth Matsui, and @NSSDeviations with Hilary Parker and Roger Peng, to list a few) and the goal here is to pass some of it along to my students rather than to come up with a comprehensive list.</summary></entry></feed>